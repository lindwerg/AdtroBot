---
phase: 15-monitoring-observability
plan: 02
type: execute
wave: 2
depends_on: ["15-01"]
files_modified:
  - src/monitoring/cost_tracking.py
  - src/services/ai/client.py
  - src/admin/services/monitoring.py
  - src/admin/schemas.py
  - src/admin/router.py
autonomous: true

must_haves:
  truths:
    - "Каждый AI запрос записывает usage data в AIUsage таблицу"
    - "Admin API /monitoring endpoint возвращает Bot Health и API Costs"
    - "DAU/WAU/MAU рассчитываются корректно"
  artifacts:
    - path: "src/monitoring/cost_tracking.py"
      provides: "Cost tracking utilities"
      exports: ["record_ai_usage"]
    - path: "src/admin/services/monitoring.py"
      provides: "Monitoring data aggregation"
      exports: ["get_monitoring_data", "get_api_costs_data"]
    - path: "src/admin/schemas.py"
      provides: "MonitoringResponse schema"
      contains: "class MonitoringResponse"
  key_links:
    - from: "src/services/ai/client.py"
      to: "src/monitoring/cost_tracking.py"
      via: "record_ai_usage call after AI response"
      pattern: "record_ai_usage"
    - from: "src/admin/router.py"
      to: "src/admin/services/monitoring.py"
      via: "GET /admin/monitoring endpoint"
      pattern: "get_monitoring_data"
---

<objective>
Интеграция cost tracking в AIService и создание admin API endpoints для мониторинга.

Purpose: Записывать все AI costs и предоставлять данные для monitoring dashboard.
Output: Работающий cost tracking, /admin/monitoring endpoint с Bot Health и API Costs.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/15-monitoring-observability/15-01-SUMMARY.md
@src/services/ai/client.py
@src/admin/router.py
@src/admin/schemas.py
@src/admin/services/analytics.py
@src/db/models/ai_usage.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Cost tracking module + AIService integration</name>
  <files>src/monitoring/cost_tracking.py, src/services/ai/client.py</files>
  <action>
1. Создать `src/monitoring/cost_tracking.py`:
```python
"""AI cost tracking utilities."""
import time
from typing import Any

import structlog
from sqlalchemy.ext.asyncio import AsyncSession

from src.db.models.ai_usage import AIUsage
from src.monitoring.metrics import (
    AI_COST_TOTAL,
    AI_REQUEST_DURATION,
    AI_REQUESTS_TOTAL,
    AI_TOKENS_TOTAL,
)

logger = structlog.get_logger()

# GPT-4o-mini pricing (per 1M tokens) - fallback if cost not in response
GPT4O_MINI_PRICING = {
    "prompt": 0.15 / 1_000_000,      # $0.15 per 1M input tokens
    "completion": 0.60 / 1_000_000,  # $0.60 per 1M output tokens
}


async def record_ai_usage(
    session: AsyncSession,
    user_id: int | None,
    operation: str,
    model: str,
    response: Any,
    latency_ms: int,
) -> None:
    """Record AI usage to database and update Prometheus metrics.

    Args:
        session: Database session
        user_id: User ID (None for system operations like background horoscope generation)
        operation: Operation type (horoscope, tarot, natal_chart, etc.)
        model: Model name (e.g., "openai/gpt-4o-mini")
        response: OpenAI/OpenRouter response object
        latency_ms: Request duration in milliseconds
    """
    try:
        usage = response.usage
        prompt_tokens = usage.prompt_tokens
        completion_tokens = usage.completion_tokens
        total_tokens = usage.total_tokens

        # Try to get cost from OpenRouter response, fallback to calculation
        cost_dollars = None
        if hasattr(response, "x_openrouter"):
            cost_dollars = response.x_openrouter.get("cost")

        if cost_dollars is None:
            # Calculate based on token pricing
            cost_dollars = (
                prompt_tokens * GPT4O_MINI_PRICING["prompt"] +
                completion_tokens * GPT4O_MINI_PRICING["completion"]
            )

        generation_id = getattr(response, "id", None)

        # Record to database
        ai_usage = AIUsage(
            user_id=user_id,
            operation=operation,
            model=model,
            prompt_tokens=prompt_tokens,
            completion_tokens=completion_tokens,
            total_tokens=total_tokens,
            cost_dollars=cost_dollars,
            generation_id=generation_id,
            latency_ms=latency_ms,
        )
        session.add(ai_usage)
        await session.commit()

        # Update Prometheus metrics
        model_short = model.split("/")[-1] if "/" in model else model

        AI_TOKENS_TOTAL.labels(
            operation=operation,
            model=model_short,
            token_type="prompt"
        ).inc(prompt_tokens)

        AI_TOKENS_TOTAL.labels(
            operation=operation,
            model=model_short,
            token_type="completion"
        ).inc(completion_tokens)

        if cost_dollars:
            AI_COST_TOTAL.labels(
                operation=operation,
                model=model_short
            ).inc(cost_dollars)

        AI_REQUEST_DURATION.labels(
            operation=operation,
            model=model_short
        ).observe(latency_ms / 1000)  # Convert to seconds

        AI_REQUESTS_TOTAL.labels(
            operation=operation,
            model=model_short,
            status="success"
        ).inc()

        logger.debug(
            "ai_usage_recorded",
            user_id=user_id,
            operation=operation,
            tokens=total_tokens,
            cost=cost_dollars,
            latency_ms=latency_ms,
        )

    except Exception as e:
        logger.error("failed_to_record_ai_usage", error=str(e))
        # Don't raise - cost tracking failure shouldn't break AI response


def record_ai_error(operation: str, model: str, error_type: str) -> None:
    """Record AI error to Prometheus metrics."""
    model_short = model.split("/")[-1] if "/" in model else model
    AI_REQUESTS_TOTAL.labels(
        operation=operation,
        model=model_short,
        status="error"
    ).inc()
```

2. Обновить `src/services/ai/client.py`:

a) Добавить imports в начало файла:
```python
import time
from src.db.engine import AsyncSessionLocal
from src.monitoring.cost_tracking import record_ai_usage, record_ai_error
```

b) Модифицировать метод `_generate` для возврата response object вместо только content.
   Создать новый internal метод `_generate_with_tracking`:

```python
async def _generate_with_tracking(
    self,
    system_prompt: str,
    user_prompt: str,
    max_tokens: int = 1500,
    operation: str = "unknown",
    user_id: int | None = None,
) -> str | None:
    """Generate AI response with usage tracking.

    Args:
        system_prompt: System instructions for the model
        user_prompt: User message/query
        max_tokens: Maximum tokens in response
        operation: Operation type for cost tracking
        user_id: User ID for cost attribution

    Returns:
        Generated text or None on API error
    """
    start_time = time.monotonic()
    try:
        response = await self.client.chat.completions.create(
            model=self.model,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt},
            ],
            max_tokens=max_tokens,
            temperature=0.8,
            extra_headers={
                "HTTP-Referer": "https://t.me/adtrobot",
                "X-Title": "AdtroBot - Astrology & Tarot",
            },
        )
        latency_ms = int((time.monotonic() - start_time) * 1000)

        # Record usage asynchronously (don't block response)
        async with AsyncSessionLocal() as session:
            await record_ai_usage(
                session=session,
                user_id=user_id,
                operation=operation,
                model=self.model,
                response=response,
                latency_ms=latency_ms,
            )

        content = response.choices[0].message.content
        return content
    except APIError as e:
        record_ai_error(operation, self.model, type(e).__name__)
        logger.error(
            "ai_generation_failed",
            error=str(e),
            status_code=getattr(e, "status_code", None),
            operation=operation,
        )
        return None
```

c) Обновить все публичные методы для передачи operation и user_id:

- `generate_horoscope`: добавить параметр `user_id: int | None = None`, вызывать `_generate_with_tracking(..., operation="horoscope", user_id=user_id)`
- `generate_tarot_interpretation`: добавить `user_id: int | None = None`, operation="tarot"
- `generate_card_of_day`: уже имеет user_id, operation="card_of_day"
- `generate_premium_horoscope`: уже имеет user_id, operation="premium_horoscope"
- `generate_celtic_cross`: добавить `user_id: int | None = None`, operation="celtic_cross"
- `generate_natal_interpretation`: уже имеет user_id, operation="natal_interpretation"
- `generate_detailed_natal_interpretation`: уже имеет user_id, operation="detailed_natal"

d) Удалить старый `_generate` метод или оставить для backward compatibility (вызывать `_generate_with_tracking` с operation="unknown").

ВАЖНО: Сохранить существующую логику caching и validation - только добавить tracking после успешного ответа.
  </action>
  <verify>
- После вызова любого AI метода (horoscope, tarot, etc.) запись появляется в ai_usage таблице
- `SELECT COUNT(*) FROM ai_usage;` увеличивается после каждого AI запроса
- Prometheus metrics /metrics содержат adtrobot_ai_tokens_total, adtrobot_ai_cost_dollars_total
  </verify>
  <done>Cost tracking записывает каждый AI запрос в БД и обновляет Prometheus metrics.</done>
</task>

<task type="auto">
  <name>Task 2: Admin monitoring service + schemas</name>
  <files>src/admin/services/monitoring.py, src/admin/schemas.py</files>
  <action>
1. Создать `src/admin/services/monitoring.py`:
```python
"""Monitoring data aggregation for admin dashboard."""
from datetime import datetime, timedelta, timezone
from typing import Literal

from sqlalchemy import distinct, func, select
from sqlalchemy.ext.asyncio import AsyncSession

from src.db.models.ai_usage import AIUsage
from src.db.models.tarot_spread import TarotSpread
from src.db.models.user import User


TimeRange = Literal["24h", "7d", "30d"]


def get_time_range_start(range_type: TimeRange) -> datetime:
    """Get start datetime for time range."""
    now = datetime.now(timezone.utc)
    if range_type == "24h":
        return now - timedelta(hours=24)
    elif range_type == "7d":
        return now - timedelta(days=7)
    else:  # 30d
        return now - timedelta(days=30)


async def get_active_users(
    session: AsyncSession,
    range_type: TimeRange,
) -> dict[str, int]:
    """Get DAU/WAU/MAU based on tarot spreads activity.

    Returns dict with dau, wau, mau counts.
    """
    now = datetime.now(timezone.utc)
    today_start = now.replace(hour=0, minute=0, second=0, microsecond=0)
    week_ago = now - timedelta(days=7)
    month_ago = now - timedelta(days=30)

    # DAU - users with activity today
    dau = await session.scalar(
        select(func.count(distinct(TarotSpread.user_id)))
        .where(TarotSpread.created_at >= today_start)
    ) or 0

    # WAU - users with activity in last 7 days
    wau = await session.scalar(
        select(func.count(distinct(TarotSpread.user_id)))
        .where(TarotSpread.created_at >= week_ago)
    ) or 0

    # MAU - users with activity in last 30 days
    mau = await session.scalar(
        select(func.count(distinct(TarotSpread.user_id)))
        .where(TarotSpread.created_at >= month_ago)
    ) or 0

    return {"dau": dau, "wau": wau, "mau": mau}


async def get_api_costs_data(
    session: AsyncSession,
    range_type: TimeRange,
) -> dict:
    """Get API costs breakdown by operation.

    Returns dict with:
    - total_cost: float
    - total_tokens: int
    - by_operation: list of {operation, cost, tokens, requests}
    - by_day: list of {date, cost, tokens}
    """
    range_start = get_time_range_start(range_type)

    # Total cost and tokens
    totals = await session.execute(
        select(
            func.coalesce(func.sum(AIUsage.cost_dollars), 0).label("total_cost"),
            func.coalesce(func.sum(AIUsage.total_tokens), 0).label("total_tokens"),
            func.count(AIUsage.id).label("total_requests"),
        )
        .where(AIUsage.created_at >= range_start)
    )
    total_row = totals.first()

    # Breakdown by operation
    by_operation_query = (
        select(
            AIUsage.operation,
            func.coalesce(func.sum(AIUsage.cost_dollars), 0).label("cost"),
            func.coalesce(func.sum(AIUsage.total_tokens), 0).label("tokens"),
            func.count(AIUsage.id).label("requests"),
        )
        .where(AIUsage.created_at >= range_start)
        .group_by(AIUsage.operation)
        .order_by(func.sum(AIUsage.cost_dollars).desc())
    )
    by_operation_result = await session.execute(by_operation_query)
    by_operation = [
        {
            "operation": row.operation or "unknown",
            "cost": float(row.cost),
            "tokens": int(row.tokens),
            "requests": int(row.requests),
        }
        for row in by_operation_result.all()
    ]

    # Breakdown by day (for chart)
    by_day_query = (
        select(
            func.date_trunc("day", AIUsage.created_at).label("day"),
            func.coalesce(func.sum(AIUsage.cost_dollars), 0).label("cost"),
            func.coalesce(func.sum(AIUsage.total_tokens), 0).label("tokens"),
        )
        .where(AIUsage.created_at >= range_start)
        .group_by(func.date_trunc("day", AIUsage.created_at))
        .order_by(func.date_trunc("day", AIUsage.created_at))
    )
    by_day_result = await session.execute(by_day_query)
    by_day = [
        {
            "date": row.day.strftime("%Y-%m-%d"),
            "cost": float(row.cost),
            "tokens": int(row.tokens),
        }
        for row in by_day_result.all()
    ]

    return {
        "total_cost": float(total_row.total_cost) if total_row else 0,
        "total_tokens": int(total_row.total_tokens) if total_row else 0,
        "total_requests": int(total_row.total_requests) if total_row else 0,
        "by_operation": by_operation,
        "by_day": by_day,
    }


async def get_unit_economics(
    session: AsyncSession,
    range_type: TimeRange,
) -> dict:
    """Get unit economics: cost per user metrics.

    Returns dict with:
    - cost_per_dau: float
    - cost_per_paying_user: float
    - total_users: int
    - paying_users: int
    """
    from src.db.models.payment import Payment

    range_start = get_time_range_start(range_type)

    # Get total cost in period
    total_cost = await session.scalar(
        select(func.coalesce(func.sum(AIUsage.cost_dollars), 0))
        .where(AIUsage.created_at >= range_start)
    ) or 0

    # Get active users in period
    active_users = await session.scalar(
        select(func.count(distinct(TarotSpread.user_id)))
        .where(TarotSpread.created_at >= range_start)
    ) or 0

    # Get paying users (ever paid)
    paying_users = await session.scalar(
        select(func.count(distinct(Payment.user_id)))
        .where(Payment.status == "succeeded")
    ) or 0

    # Active paying users in period
    active_paying = await session.scalar(
        select(func.count(distinct(TarotSpread.user_id)))
        .where(TarotSpread.created_at >= range_start)
        .where(
            TarotSpread.user_id.in_(
                select(distinct(Payment.user_id))
                .where(Payment.status == "succeeded")
            )
        )
    ) or 0

    return {
        "total_cost": float(total_cost),
        "active_users": active_users,
        "paying_users": paying_users,
        "active_paying_users": active_paying,
        "cost_per_active_user": float(total_cost) / max(active_users, 1),
        "cost_per_paying_user": float(total_cost) / max(active_paying, 1),
    }


async def get_error_stats(
    session: AsyncSession,
    range_type: TimeRange,
) -> dict:
    """Get error statistics (placeholder - from Prometheus or logs).

    For now returns zeros - real implementation would query Prometheus or logs.
    """
    # TODO: Query Prometheus for actual error rates
    return {
        "error_count": 0,
        "error_rate": 0.0,
        "avg_response_time_ms": 0,
    }


async def get_monitoring_data(
    session: AsyncSession,
    range_type: TimeRange = "7d",
) -> dict:
    """Get all monitoring data for dashboard.

    Combines active users, API costs, unit economics, error stats.
    """
    active_users = await get_active_users(session, range_type)
    api_costs = await get_api_costs_data(session, range_type)
    unit_economics = await get_unit_economics(session, range_type)
    error_stats = await get_error_stats(session, range_type)

    return {
        "range": range_type,
        "active_users": active_users,
        "api_costs": api_costs,
        "unit_economics": unit_economics,
        "error_stats": error_stats,
    }
```

2. Добавить schemas в `src/admin/schemas.py`:

В конец файла добавить:
```python
# === Monitoring Schemas ===


class ActiveUsersMetrics(BaseModel):
    """Active users metrics: DAU/WAU/MAU."""
    dau: int
    wau: int
    mau: int


class CostByOperation(BaseModel):
    """Cost breakdown by operation type."""
    operation: str
    cost: float
    tokens: int
    requests: int


class CostByDay(BaseModel):
    """Daily cost data for charts."""
    date: str  # YYYY-MM-DD
    cost: float
    tokens: int


class APICostsData(BaseModel):
    """API costs breakdown."""
    total_cost: float
    total_tokens: int
    total_requests: int
    by_operation: list[CostByOperation]
    by_day: list[CostByDay]


class UnitEconomicsData(BaseModel):
    """Unit economics metrics."""
    total_cost: float
    active_users: int
    paying_users: int
    active_paying_users: int
    cost_per_active_user: float
    cost_per_paying_user: float


class ErrorStatsData(BaseModel):
    """Error statistics."""
    error_count: int
    error_rate: float
    avg_response_time_ms: int


class MonitoringResponse(BaseModel):
    """Full monitoring data response."""
    range: str  # 24h, 7d, 30d
    active_users: ActiveUsersMetrics
    api_costs: APICostsData
    unit_economics: UnitEconomicsData
    error_stats: ErrorStatsData
```
  </action>
  <verify>
- `from src.admin.services.monitoring import get_monitoring_data` не падает
- `from src.admin.schemas import MonitoringResponse` не падает
- Функции возвращают корректную структуру данных
  </verify>
  <done>Monitoring service и schemas созданы для агрегации данных.</done>
</task>

<task type="auto">
  <name>Task 3: Admin /monitoring endpoint</name>
  <files>src/admin/router.py</files>
  <action>
1. Добавить импорты в начало `src/admin/router.py`:
```python
from src.admin.services.monitoring import get_monitoring_data
from src.admin.schemas import MonitoringResponse
```

2. Добавить endpoint перед `# Export endpoints` секцией (после Experiments):
```python
# === Monitoring Endpoints ===


@admin_router.get("/monitoring", response_model=MonitoringResponse)
async def monitoring_dashboard(
    range: str = Query("7d", regex="^(24h|7d|30d)$", description="Time range"),
    session: AsyncSession = Depends(get_session),
    current_admin: Admin = Depends(get_current_admin),
) -> MonitoringResponse:
    """Get monitoring dashboard data.

    Args:
        range: Time range - 24h, 7d, or 30d

    Returns:
        Monitoring data with active users, API costs, unit economics
    """
    from typing import Literal
    range_type: Literal["24h", "7d", "30d"] = range  # type: ignore
    data = await get_monitoring_data(session, range_type)
    return MonitoringResponse(**data)
```
  </action>
  <verify>
- `curl -H "Authorization: Bearer $TOKEN" http://localhost:8000/admin/monitoring` возвращает JSON
- `curl -H "Authorization: Bearer $TOKEN" http://localhost:8000/admin/monitoring?range=24h` работает
- Response содержит active_users, api_costs, unit_economics, error_stats
  </verify>
  <done>Admin API endpoint /monitoring доступен с фильтром по времени.</done>
</task>

</tasks>

<verification>
1. Сделать тестовый AI запрос (через бота или тест) и проверить:
   - `SELECT * FROM ai_usage ORDER BY id DESC LIMIT 5;` показывает записи
2. `curl http://localhost:8000/admin/monitoring?range=7d` (с auth header) возвращает:
   - active_users с dau/wau/mau
   - api_costs с by_operation и by_day
   - unit_economics с cost_per_active_user
3. Prometheus /metrics содержит обновленные adtrobot_ai_* метрики
</verification>

<success_criteria>
- Каждый AI запрос записывается в ai_usage таблицу
- /admin/monitoring возвращает полные данные мониторинга
- DAU/WAU/MAU рассчитываются из реальных данных
- Unit economics показывает cost per user
</success_criteria>

<output>
After completion, create `.planning/phases/15-monitoring-observability/15-02-SUMMARY.md`
</output>
